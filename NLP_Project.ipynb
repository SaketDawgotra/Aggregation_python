{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketDawgotra/Aggregation_python/blob/main/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD-LA7uJ7vzm"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVUrk3htevr4"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Language:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word_index_mapping = {}\n",
        "        self.word_count_mapping = {}\n",
        "        self.index_word_mapping = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word_index_mapping:\n",
        "            self.word_index_mapping[word] = self.n_words\n",
        "            self.word_count_mapping[word] = 1\n",
        "            self.index_word_mapping[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word_count_mapping[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF1mOm-Se5L8"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 50\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "class Utils:\n",
        "  def unicodeToAscii(self, s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "  def format(self, s):\n",
        "    s = self.unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "  \n",
        "  def filter_pair(self, p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "  def filter_pairs(self, pairs):\n",
        "    return [pair for pair in pairs if self.filter_pair(pair)]\n",
        "\n",
        "utils = Utils()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQc-UAsXfqix"
      },
      "outputs": [],
      "source": [
        "def read_languages(lang1, lang2):\n",
        "    print(\"Reading lines for language \", lang1, \"to language \", lang2 )\n",
        "    lines = open('sample_data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[utils.format(s) for s in l.split('\\t')] for l in lines]\n",
        "    print(pairs[0])\n",
        "\n",
        "    input_lang = Language(lang1)\n",
        "    output_lang = Language(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crbf-DPVhq5x",
        "outputId": "2c672e55-d451-4947-f255-b2103f3ed169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines for language  eng to language  fra\n",
            "['go .', 'va !']\n",
            "Read 135842 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 13038\n",
            "fra 21325\n",
            "['i left a message for tom .', 'j ai laisse un message pour tom .']\n"
          ]
        }
      ],
      "source": [
        "def prepare_data(lang1, lang2):\n",
        "    input_lang, output_lang, pairs = read_languages(lang1, lang2)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = utils.filter_pairs(pairs)\n",
        "    # print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "      input_lang.add_sentence(pair[0])\n",
        "      output_lang.add_sentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepare_data('eng', 'fra')\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYiNASQtkpeH"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYAgdu-hlRKk"
      },
      "outputs": [],
      "source": [
        "def get_indexes_from_sentences(lang, sentence):\n",
        "    return [lang.word_index_mapping[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def get_tensor_from_sentence(lang, sentence):\n",
        "    indexes = get_indexes_from_sentences(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def get_tensors_from_pair(pair):\n",
        "    input_tensor = get_tensor_from_sentence(input_lang, pair[0])\n",
        "    target_tensor = get_tensor_from_sentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1x08U9vluot"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuPIP2NPlzTB"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1ws61Pll9WI"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters=150000, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [get_tensors_from_pair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    # showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-rUXjXPnbyC"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = get_tensor_from_sentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index_word_mapping[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npEq7pM7pYHU"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66831ydenqsy"
      },
      "outputs": [],
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IdYXumbu9td",
        "outputId": "d85a71fd-a272-4559-84a3-6e176cefe107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 25s (- 63m 34s) (1000 0%) 5.1466\n",
            "0m 41s (- 50m 36s) (2000 1%) 4.8097\n",
            "0m 56s (- 46m 15s) (3000 2%) 4.7266\n",
            "1m 12s (- 43m 55s) (4000 2%) 4.5294\n",
            "1m 28s (- 42m 38s) (5000 3%) 4.5035\n",
            "1m 44s (- 41m 46s) (6000 4%) 4.4070\n",
            "2m 0s (- 41m 7s) (7000 4%) 4.4198\n",
            "2m 17s (- 40m 41s) (8000 5%) 4.3603\n",
            "2m 33s (- 40m 10s) (9000 6%) 4.2831\n",
            "2m 50s (- 39m 44s) (10000 6%) 4.2521\n",
            "3m 7s (- 39m 23s) (11000 7%) 4.2685\n",
            "3m 23s (- 39m 3s) (12000 8%) 4.1972\n",
            "3m 40s (- 38m 39s) (13000 8%) 4.0876\n",
            "3m 56s (- 38m 21s) (14000 9%) 4.0556\n",
            "4m 13s (- 37m 59s) (15000 10%) 3.9961\n",
            "4m 30s (- 37m 43s) (16000 10%) 3.9831\n",
            "4m 46s (- 37m 24s) (17000 11%) 3.9241\n",
            "5m 3s (- 37m 6s) (18000 12%) 3.8829\n",
            "5m 20s (- 36m 49s) (19000 12%) 3.8326\n",
            "5m 36s (- 36m 29s) (20000 13%) 3.7858\n",
            "5m 53s (- 36m 11s) (21000 14%) 3.7928\n",
            "6m 10s (- 35m 53s) (22000 14%) 3.7722\n",
            "6m 26s (- 35m 35s) (23000 15%) 3.7124\n",
            "6m 43s (- 35m 15s) (24000 16%) 3.7140\n",
            "6m 59s (- 34m 58s) (25000 16%) 3.6896\n",
            "7m 16s (- 34m 42s) (26000 17%) 3.7455\n",
            "7m 33s (- 34m 27s) (27000 18%) 3.6573\n",
            "7m 50s (- 34m 11s) (28000 18%) 3.6768\n",
            "8m 7s (- 33m 54s) (29000 19%) 3.6357\n",
            "8m 24s (- 33m 36s) (30000 20%) 3.6655\n",
            "8m 40s (- 33m 19s) (31000 20%) 3.5664\n",
            "8m 57s (- 33m 3s) (32000 21%) 3.6333\n",
            "9m 14s (- 32m 45s) (33000 22%) 3.5160\n",
            "9m 31s (- 32m 28s) (34000 22%) 3.5081\n",
            "9m 47s (- 32m 11s) (35000 23%) 3.5306\n",
            "10m 4s (- 31m 55s) (36000 24%) 3.4338\n",
            "10m 21s (- 31m 38s) (37000 24%) 3.4874\n",
            "10m 38s (- 31m 22s) (38000 25%) 3.4315\n",
            "10m 55s (- 31m 5s) (39000 26%) 3.3954\n",
            "11m 11s (- 30m 47s) (40000 26%) 3.3747\n",
            "11m 28s (- 30m 30s) (41000 27%) 3.4559\n",
            "11m 45s (- 30m 13s) (42000 28%) 3.3028\n",
            "12m 2s (- 29m 56s) (43000 28%) 3.4187\n",
            "12m 18s (- 29m 39s) (44000 29%) 3.3049\n",
            "12m 35s (- 29m 21s) (45000 30%) 3.4076\n",
            "12m 51s (- 29m 5s) (46000 30%) 3.3329\n",
            "13m 8s (- 28m 48s) (47000 31%) 3.3335\n",
            "13m 25s (- 28m 32s) (48000 32%) 3.3192\n",
            "13m 42s (- 28m 15s) (49000 32%) 3.2971\n",
            "13m 59s (- 27m 58s) (50000 33%) 3.2620\n",
            "14m 15s (- 27m 41s) (51000 34%) 3.2221\n",
            "14m 32s (- 27m 24s) (52000 34%) 3.2666\n",
            "14m 49s (- 27m 7s) (53000 35%) 3.2258\n",
            "15m 6s (- 26m 50s) (54000 36%) 3.1336\n",
            "15m 22s (- 26m 33s) (55000 36%) 3.2024\n",
            "15m 39s (- 26m 17s) (56000 37%) 3.2108\n",
            "15m 56s (- 26m 1s) (57000 38%) 3.1628\n",
            "16m 13s (- 25m 44s) (58000 38%) 3.1777\n",
            "16m 30s (- 25m 27s) (59000 39%) 3.2103\n",
            "16m 47s (- 25m 11s) (60000 40%) 3.2043\n",
            "17m 4s (- 24m 54s) (61000 40%) 3.1693\n",
            "17m 20s (- 24m 37s) (62000 41%) 3.1546\n",
            "17m 37s (- 24m 20s) (63000 42%) 3.1517\n",
            "17m 54s (- 24m 3s) (64000 42%) 3.1457\n",
            "18m 11s (- 23m 47s) (65000 43%) 3.0808\n",
            "18m 28s (- 23m 30s) (66000 44%) 3.1275\n",
            "18m 45s (- 23m 13s) (67000 44%) 3.0777\n",
            "19m 1s (- 22m 56s) (68000 45%) 3.1465\n",
            "19m 18s (- 22m 40s) (69000 46%) 3.1533\n",
            "19m 35s (- 22m 23s) (70000 46%) 3.1278\n",
            "19m 52s (- 22m 6s) (71000 47%) 3.1081\n",
            "20m 9s (- 21m 50s) (72000 48%) 3.0578\n",
            "20m 26s (- 21m 33s) (73000 48%) 3.0698\n",
            "20m 42s (- 21m 16s) (74000 49%) 3.0286\n",
            "20m 59s (- 20m 59s) (75000 50%) 3.0209\n",
            "21m 16s (- 20m 43s) (76000 50%) 3.0185\n",
            "21m 33s (- 20m 26s) (77000 51%) 3.0702\n",
            "21m 50s (- 20m 9s) (78000 52%) 3.0922\n",
            "22m 6s (- 19m 52s) (79000 52%) 3.0091\n",
            "22m 23s (- 19m 35s) (80000 53%) 3.0352\n",
            "22m 40s (- 19m 18s) (81000 54%) 3.0655\n",
            "22m 57s (- 19m 2s) (82000 54%) 3.0821\n",
            "23m 14s (- 18m 45s) (83000 55%) 3.0136\n",
            "23m 31s (- 18m 28s) (84000 56%) 2.9783\n",
            "23m 47s (- 18m 11s) (85000 56%) 2.9531\n",
            "24m 4s (- 17m 55s) (86000 57%) 2.9873\n",
            "24m 21s (- 17m 38s) (87000 57%) 2.9567\n",
            "24m 38s (- 17m 21s) (88000 58%) 2.9837\n",
            "24m 55s (- 17m 5s) (89000 59%) 3.0100\n",
            "25m 12s (- 16m 48s) (90000 60%) 2.9551\n",
            "25m 29s (- 16m 31s) (91000 60%) 2.9913\n",
            "25m 46s (- 16m 14s) (92000 61%) 2.9536\n",
            "26m 3s (- 15m 58s) (93000 62%) 2.9745\n",
            "26m 20s (- 15m 41s) (94000 62%) 2.8795\n",
            "26m 37s (- 15m 24s) (95000 63%) 2.9255\n",
            "26m 53s (- 15m 7s) (96000 64%) 2.8505\n",
            "27m 10s (- 14m 51s) (97000 64%) 2.9084\n",
            "27m 27s (- 14m 34s) (98000 65%) 2.9315\n",
            "27m 44s (- 14m 17s) (99000 66%) 2.8991\n",
            "28m 1s (- 14m 0s) (100000 66%) 2.9187\n",
            "28m 18s (- 13m 43s) (101000 67%) 2.9304\n",
            "28m 35s (- 13m 27s) (102000 68%) 2.9668\n",
            "28m 52s (- 13m 10s) (103000 68%) 2.9208\n",
            "29m 9s (- 12m 53s) (104000 69%) 2.8814\n",
            "29m 26s (- 12m 36s) (105000 70%) 2.8627\n",
            "29m 42s (- 12m 20s) (106000 70%) 2.8477\n",
            "29m 59s (- 12m 3s) (107000 71%) 2.9086\n",
            "30m 16s (- 11m 46s) (108000 72%) 2.9048\n",
            "30m 33s (- 11m 29s) (109000 72%) 2.8998\n",
            "30m 50s (- 11m 13s) (110000 73%) 2.8945\n",
            "31m 7s (- 10m 56s) (111000 74%) 2.8576\n",
            "31m 24s (- 10m 39s) (112000 74%) 2.8514\n",
            "31m 41s (- 10m 22s) (113000 75%) 2.7698\n",
            "31m 58s (- 10m 5s) (114000 76%) 2.8487\n",
            "32m 15s (- 9m 49s) (115000 76%) 2.8898\n",
            "32m 32s (- 9m 32s) (116000 77%) 2.8138\n",
            "32m 49s (- 9m 15s) (117000 78%) 2.9165\n",
            "33m 6s (- 8m 58s) (118000 78%) 2.8351\n",
            "33m 23s (- 8m 41s) (119000 79%) 2.8629\n",
            "33m 40s (- 8m 25s) (120000 80%) 2.8564\n",
            "33m 57s (- 8m 8s) (121000 80%) 2.8915\n",
            "34m 14s (- 7m 51s) (122000 81%) 2.8734\n",
            "34m 31s (- 7m 34s) (123000 82%) 2.7596\n",
            "34m 48s (- 7m 17s) (124000 82%) 2.8370\n",
            "35m 5s (- 7m 1s) (125000 83%) 2.8751\n",
            "35m 22s (- 6m 44s) (126000 84%) 2.7666\n",
            "35m 39s (- 6m 27s) (127000 84%) 2.7797\n",
            "35m 55s (- 6m 10s) (128000 85%) 2.7251\n",
            "36m 12s (- 5m 53s) (129000 86%) 2.7396\n",
            "36m 29s (- 5m 36s) (130000 86%) 2.7260\n",
            "36m 46s (- 5m 20s) (131000 87%) 2.7158\n",
            "37m 3s (- 5m 3s) (132000 88%) 2.7901\n",
            "37m 20s (- 4m 46s) (133000 88%) 2.7461\n",
            "37m 37s (- 4m 29s) (134000 89%) 2.6664\n",
            "37m 54s (- 4m 12s) (135000 90%) 2.7501\n",
            "38m 11s (- 3m 55s) (136000 90%) 2.7625\n",
            "38m 28s (- 3m 39s) (137000 91%) 2.7933\n",
            "38m 45s (- 3m 22s) (138000 92%) 2.7726\n",
            "39m 2s (- 3m 5s) (139000 92%) 2.7723\n",
            "39m 19s (- 2m 48s) (140000 93%) 2.7583\n",
            "39m 36s (- 2m 31s) (141000 94%) 2.7153\n",
            "39m 53s (- 2m 14s) (142000 94%) 2.7608\n",
            "40m 9s (- 1m 57s) (143000 95%) 2.7423\n",
            "40m 26s (- 1m 41s) (144000 96%) 2.7197\n",
            "40m 43s (- 1m 24s) (145000 96%) 2.7146\n",
            "41m 0s (- 1m 7s) (146000 97%) 2.7589\n",
            "41m 17s (- 0m 50s) (147000 98%) 2.7516\n",
            "41m 34s (- 0m 33s) (148000 98%) 2.7842\n",
            "41m 51s (- 0m 16s) (149000 99%) 2.7654\n",
            "42m 9s (- 0m 0s) (150000 100%) 2.6961\n"
          ]
        }
      ],
      "source": [
        "trainIters(encoder1, attn_decoder1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5AGn4as5MZp",
        "outputId": "fe3302e9-25f5-4656-f708-6c4067d17136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> i thought you of all people would understand my decision .\n",
            "= je pensais que toi entre tous comprendrait ma decision .\n",
            "< je pensais que tu me pris tous mes gens . . <EOS>\n",
            "\n",
            "> i dislike coffee .\n",
            "= je n aime pas le cafe .\n",
            "< je m du cafe . <EOS>\n",
            "\n",
            "> do you know who wrote this book ?\n",
            "= est ce que tu sais qui a ecrit ce livre ?\n",
            "< savez vous qui ecrit ce qui ecrit ecrit ? <EOS>\n",
            "\n",
            "> she made it plain that she wanted to go to college .\n",
            "= elle fit clairement comprendre qu elle voulait aller a l universite .\n",
            "< elle a qu elle voulait aller a l ecole . <EOS>\n",
            "\n",
            "> tom is even scared of mary .\n",
            "= tom a meme peur de mary .\n",
            "< tom est mort de l . <EOS>\n",
            "\n",
            "> you look depressed . did something happen ?\n",
            "= tu as l air deprimee quelque chose est il survenu ?\n",
            "< tu as l air ce qui il a quelque chose ? <EOS>\n",
            "\n",
            "> he kicked the ball with his foot .\n",
            "= il tira dans le ballon avec son pied .\n",
            "< il a son le le le le . . . <EOS>\n",
            "\n",
            "> it is very kind of you to invite me .\n",
            "= c est tres aimable a vous de m inviter .\n",
            "< il est tres gentil de m m a vous <EOS>\n",
            "\n",
            "> get on your knees .\n",
            "= agenouillez vous !\n",
            "< mets toi de votre ! <EOS>\n",
            "\n",
            "> she has a bad habit of talking a long time on the phone .\n",
            "= elle a la mauvaise habitude de parler longtemps au telephone .\n",
            "< elle a un long de l . . <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}